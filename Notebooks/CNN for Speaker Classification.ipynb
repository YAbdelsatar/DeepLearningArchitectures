{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.io.wavfile\n",
    "from scipy.fftpack import dct\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import plaidml.keras\n",
    "\n",
    "plaidml.keras.install_backend()\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Define Pre Processing Function</h1>\n",
    "\n",
    "This function will apply all of the necessary pre-processsing to the speech signal. It assumes that we've already cut the speech signal down to 3 seconds. Then:\n",
    "\n",
    "- Apply Pre-emphasis\n",
    "- Framing\n",
    "- Framing\n",
    "- Hamming Window\n",
    "- Fourier Spectrum\n",
    "- Log-Mel Filter Banks\n",
    "- MFCC scale\n",
    "- Normalization\n",
    "\n",
    "The function will happily accept larger segments but it will still spit out the same length vector which will confuse the network.\n",
    "\n",
    "I think a lot of this can be done with Tensorflow function which are probably a bit faster since just the pre-processing takes some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preprocessing(signal):\n",
    "\n",
    "    pre_emphasis = 0.97\n",
    "    emphasized_signal = numpy.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\n",
    "\n",
    "    frame_size = .025\n",
    "    frame_stride = 0.01\n",
    "\n",
    "    frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate  # Convert from seconds to samples\n",
    "    signal_length = len(emphasized_signal)\n",
    "    frame_length = int(round(frame_length))\n",
    "    frame_step = int(round(frame_step))\n",
    "    num_frames = int(numpy.ceil(float(numpy.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
    "\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    z = numpy.zeros((pad_signal_length - signal_length))\n",
    "    pad_signal = numpy.append(emphasized_signal, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
    "\n",
    "    indices = numpy.tile(numpy.arange(0, frame_length), (num_frames, 1)) + numpy.tile(numpy.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    frames = pad_signal[indices.astype(numpy.int32, copy=False)]\n",
    "    frames *= numpy.hamming(frame_length)\n",
    "    # frames *= 0.54 - 0.46 * numpy.cos((2 * numpy.pi * n) / (frame_length - 1))  # Explicit Implementation **\n",
    "    NFFT = 512\n",
    "\n",
    "    mag_frames = numpy.absolute(numpy.fft.rfft(frames, NFFT))  # Magnitude of the FFT\n",
    "    pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))  # Power Spectrum\n",
    "\n",
    "    nfilt = 40\n",
    "\n",
    "    low_freq_mel = 0\n",
    "    high_freq_mel = (2595 * numpy.log10(1 + (sample_rate / 2) / 700))  # Convert Hz to Mel\n",
    "    mel_points = numpy.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\n",
    "    hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\n",
    "    bin = numpy.floor((NFFT + 1) * hz_points / sample_rate)\n",
    "\n",
    "    fbank = numpy.zeros((nfilt, int(numpy.floor(NFFT / 2 + 1))))\n",
    "    for m in range(1, nfilt + 1):\n",
    "        f_m_minus = int(bin[m - 1])   # left\n",
    "        f_m = int(bin[m])             # center\n",
    "        f_m_plus = int(bin[m + 1])    # right\n",
    "\n",
    "        for k in range(f_m_minus, f_m):\n",
    "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "        for k in range(f_m, f_m_plus):\n",
    "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "    filter_banks = numpy.dot(pow_frames, fbank.T)\n",
    "    filter_banks = numpy.where(filter_banks == 0, numpy.finfo(float).eps, filter_banks)  # Numerical Stability\n",
    "    filter_banks = 20 * numpy.log10(filter_banks)  # dB\n",
    "\n",
    "    mfcc = dct(filter_banks, type=2, axis=1, norm='ortho')\n",
    "\n",
    "    mfcc -= (numpy.mean(mfcc, axis=0) + 1e-8)\n",
    "    \n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Importing and Preprocessing Some Data</h1>\n",
    "\n",
    "I decided to go with 20 speakers to start off with. We are taking their names, locating all the files under their names and applying the 3-second windows to each file so we get out a list of tensors and speaker ID's. Our end result will be a TF dataset that we can directly apply to train our network.\n",
    "\n",
    "Unfortunately, the real dataset is around 36GB, which will be too big to fit in RAM. We'll need some way to break it up in order to use it to train our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"../Datasets/vox1_meta.csv\", delimiter = '\\t', index_col = \"VoxCeleb1 ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 records processed so far...\n",
      "200 records processed so far...\n",
      "300 records processed so far...\n",
      "400 records processed so far...\n",
      "500 records processed so far...\n",
      "600 records processed so far...\n",
      "700 records processed so far...\n",
      "800 records processed so far...\n",
      "900 records processed so far...\n",
      "1000 records processed so far...\n",
      "1100 records processed so far...\n",
      "1200 records processed so far...\n",
      "1300 records processed so far...\n",
      "1400 records processed so far...\n",
      "1500 records processed so far...\n",
      "1600 records processed so far...\n",
      "1700 records processed so far...\n",
      "1800 records processed so far...\n",
      "1900 records processed so far...\n",
      "2000 records processed so far...\n",
      "2100 records processed so far...\n",
      "2200 records processed so far...\n",
      "2300 records processed so far...\n",
      "2400 records processed so far...\n",
      "2500 records processed so far...\n",
      "2600 records processed so far...\n",
      "2700 records processed so far...\n",
      "2800 records processed so far...\n",
      "2900 records processed so far...\n",
      "3000 records processed so far...\n",
      "3100 records processed so far...\n",
      "3200 records processed so far...\n",
      "3300 records processed so far...\n",
      "3400 records processed so far...\n",
      "3500 records processed so far...\n",
      "3600 records processed so far...\n",
      "3700 records processed so far...\n",
      "3800 records processed so far...\n",
      "3900 records processed so far...\n",
      "4000 records processed so far...\n",
      "4100 records processed so far...\n",
      "4200 records processed so far...\n",
      "4300 records processed so far...\n",
      "4400 records processed so far...\n",
      "4500 records processed so far...\n",
      "4600 records processed so far...\n",
      "4700 records processed so far...\n",
      "4800 records processed so far...\n",
      "4900 records processed so far...\n",
      "5000 records processed so far...\n",
      "5100 records processed so far...\n",
      "5200 records processed so far...\n",
      "5300 records processed so far...\n",
      "5400 records processed so far...\n",
      "5500 records processed so far...\n",
      "5600 records processed so far...\n",
      "5700 records processed so far...\n",
      "5800 records processed so far...\n",
      "5900 records processed so far...\n",
      "6000 records processed so far...\n",
      "6100 records processed so far...\n",
      "6200 records processed so far...\n",
      "6300 records processed so far...\n",
      "6400 records processed so far...\n",
      "6500 records processed so far...\n",
      "6600 records processed so far...\n",
      "6700 records processed so far...\n",
      "6800 records processed so far...\n",
      "6900 records processed so far...\n",
      "7000 records processed so far...\n",
      "7100 records processed so far...\n",
      "7200 records processed so far...\n",
      "7300 records processed so far...\n",
      "7400 records processed so far...\n",
      "7500 records processed so far...\n",
      "7600 records processed so far...\n",
      "7700 records processed so far...\n",
      "7800 records processed so far...\n",
      "7900 records processed so far...\n",
      "8000 records processed so far...\n",
      "8100 records processed so far...\n",
      "8200 records processed so far...\n",
      "8300 records processed so far...\n",
      "8400 records processed so far...\n",
      "8500 records processed so far...\n",
      "8600 records processed so far...\n",
      "8700 records processed so far...\n",
      "8800 records processed so far...\n",
      "8900 records processed so far...\n",
      "9000 records processed so far...\n",
      "9100 records processed so far...\n",
      "9200 records processed so far...\n",
      "9300 records processed so far...\n",
      "9400 records processed so far...\n",
      "9500 records processed so far...\n",
      "9600 records processed so far...\n",
      "9700 records processed so far...\n",
      "9800 records processed so far...\n",
      "9900 records processed so far...\n",
      "10000 records processed so far...\n",
      "10100 records processed so far...\n",
      "10200 records processed so far...\n",
      "10300 records processed so far...\n",
      "10400 records processed so far...\n",
      "10500 records processed so far...\n",
      "10600 records processed so far...\n",
      "10700 records processed so far...\n",
      "10800 records processed so far...\n",
      "10900 records processed so far...\n",
      "11000 records processed so far...\n",
      "11100 records processed so far...\n",
      "11200 records processed so far...\n",
      "11300 records processed so far...\n",
      "11400 records processed so far...\n",
      "11500 records processed so far...\n",
      "11600 records processed so far...\n",
      "11700 records processed so far...\n",
      "11800 records processed so far...\n",
      "11900 records processed so far...\n",
      "12000 records processed so far...\n",
      "12100 records processed so far...\n",
      "12200 records processed so far...\n"
     ]
    }
   ],
   "source": [
    "dev_loc = \"../../Dataset/vox1_dev_wav/vox1_dev_wav/wav\"\n",
    "test_loc = \"../../Dataset/wav\"\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for index in meta.iloc[0:100].index:\n",
    "    dev_path = os.path.join(dev_loc, index)\n",
    "    test_path = os.path.join(test_loc, index)\n",
    "    if os.path.exists(dev_path):\n",
    "        paths = os.walk(dev_path)\n",
    "    if os.path.exists(test_path):\n",
    "        paths = os.walk(test_path)\n",
    "    if paths != None:\n",
    "        for sub_paths in paths:\n",
    "            for file in sub_paths[2]:\n",
    "                sample_rate, signal = scipy.io.wavfile.read(os.path.join(sub_paths[0],file))\n",
    "                signals = list(zip(*[iter(signal)]*(3*sample_rate)))\n",
    "                train_x.extend([numpy.swapaxes(apply_preprocessing(numpy.array(signal)),0,1) for signal in signals])\n",
    "                train_y.extend([index]*len(signals))\n",
    "                counter += 1\n",
    "                if(counter%100 == 0):\n",
    "                    print(str(counter) + \" records processed so far...\")\n",
    "    paths = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = list(map(lambda x : x.reshape((298,40,1)), train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_ = OneHotEncoder(sparse=False).fit_transform(numpy.array(train_y).reshape(-1,1))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y_)).batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3. Building the Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19 = tf.keras.applications.VGG19(include_top=False, weights=None, input_shape=(298,40,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  #nh - output dimension of last network step\n",
    "  #nk - number of attention hops\n",
    "  #nc - hidden size of intermediate layer\n",
    "  #T  - the sequence length, since I'm sorta used to image processing that's sort of misleading, the sequence length is simply\n",
    "    #the height of the input image.\n",
    "    def __init__(self, nk=4, nc=64, initializer=tf.keras.initializers.GlorotNormal()):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.nh = None\n",
    "        self.T = None\n",
    "        self.nk = nk\n",
    "        self.nc = nc\n",
    "        self.initializer = initializer\n",
    "\n",
    "  #T - number of frames we will run through at one time\n",
    "    def build(self, input_shape):\n",
    "    #I'm expecting a tensor in this format(batch_size, height, sequence_len, num_filters)\n",
    "    #out of which I want to extract a flattened tensor height x num_filters\n",
    "    #sequence len is T\n",
    "        self.nh = input_shape[2] * input_shape[3]\n",
    "        self.W1 = self.add_weight(\n",
    "            shape=(self.nh,self.nc),\n",
    "            initializer= self.initializer,\n",
    "            trainable=True\n",
    "        )\n",
    "        self.W2 = self.add_weight(\n",
    "            shape=(self.nc, self.nk),\n",
    "            initializer= self.initializer,\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "  #H - Output of the VGG or other processing network\n",
    "    @tf.function\n",
    "    def call(self, H):\n",
    "        @tf.function\n",
    "        def operations(H):\n",
    "            H = tf.reshape(H,tf.convert_to_tensor([H.shape[0],H.shape[1]*H.shape[2]]))\n",
    "            A = tf.nn.softmax(tf.nn.tanh(tf.linalg.matmul(tf.linalg.matmul(H,self.W1),self.W2)))\n",
    "            return tf.linalg.matmul(H, A, transpose_a = True)\n",
    "        return tf.map_fn(operations, H)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(VGG19.layers[0:8])\n",
    "[model.add(layer) for layer in VGG19.layers[11:13]]\n",
    "model.add(tf.keras.layers.MaxPool2D(padding='same'))\n",
    "model.add(SelfAttention())\n",
    "model.add(tf.keras.layers.AveragePooling1D(pool_size=2, padding='same'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "413/413 [==============================] - 8086s 20s/step - loss: 4.9907 - accuracy: 0.0664\n",
      "Epoch 2/60\n",
      "413/413 [==============================] - 8641s 21s/step - loss: 8.1555 - accuracy: 0.0951\n",
      "Epoch 3/60\n",
      "413/413 [==============================] - 7757s 19s/step - loss: 3.8140 - accuracy: 0.0945\n",
      "Epoch 4/60\n",
      "413/413 [==============================] - 7752s 19s/step - loss: 4.3917 - accuracy: 0.0969\n",
      "Epoch 5/60\n",
      "413/413 [==============================] - 7673s 19s/step - loss: 4.6378 - accuracy: 0.0384\n",
      "Epoch 6/60\n",
      "413/413 [==============================] - 7662s 19s/step - loss: 4.4632 - accuracy: 0.0042\n",
      "Epoch 7/60\n",
      "186/413 [============>.................] - ETA: 1:11:30 - loss: 4.6759 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-371-31d5c9353629>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 298, 40, 64)       640       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 298, 40, 64)       36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 149, 20, 64)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 149, 20, 128)      73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 149, 20, 128)      147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 74, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 74, 10, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 5, 256)        0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 5, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 19, 3, 512)        0         \n",
      "_________________________________________________________________\n",
      "self_attention_46 (SelfAtten (None, 1536, 4)           98560     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_22 (Averag (None, 768, 4)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 2,645,284\n",
      "Trainable params: 2,645,284\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
